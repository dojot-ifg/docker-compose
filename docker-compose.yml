version: '3.8'
services:

  history:
    image: dojot/history:v0.5.0
    restart: always
    depends_on:
      - mongodb
    environment:
      FALCON_SETTINGS_MODULE: 'history.settings.docker'
      DOJOT_MANAGEMENT_USER: 'history'
      HISTORY_DB_DATA_EXPIRATION: "5356800"
      LOG_LEVEL: INFO
    logging:
      driver: json-file
      options:
        max-size: 100m

  persister:
    image: dojot/persister:v0.5.0
    restart: always
    depends_on:
      - mongodb
      - auth
      - kafka
      - data-broker
    environment:
      FALCON_SETTINGS_MODULE: 'history.settings.docker'
      DOJOT_MANAGEMENT_USER: 'persister'
      KAFKA_GROUP_ID: 'persister-group'
      LOG_LEVEL: INFO
    logging:
      driver: json-file
      options:
        max-size: 100m

  mongodb:
    image: dojot/mongo:3.2
    restart: always
    user: "mongodb"
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongo mongodb:27017/test --quiet
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 40s
    logging:
      driver: json-file
      options:
        max-size: 100m
    volumes:
      - mongodb-volume:/data/db
      - mongodb-cfg-volume:/data/configdb

  gui:
    image: dojot/gui:v0.5.0
    restart: always
    logging:
      driver: json-file
      options:
        max-size: 100m

  gui-v2:
    image: artifactory.cpqd.com.br/docker-dev/cpqd/dojot/gui-v2:2.2.2
    restart: always
    logging:
      driver: json-file
      options:
        max-size: 100m

  data-broker:
    image: dojot/data-broker:v0.5.0
    restart: always
    depends_on:
      - kafka
      - data-broker-redis
      - auth
    environment:
      DOJOT_MANAGEMENT_USER: 'data-broker'
      KAFKA_GROUP_ID: 'data-broker-group'
      SERVICE_PORT: ${DATA_BROKER_SERVICE_PORT}
      DATA_BROKER_URL: 'http://data-broker:${DATA_BROKER_SERVICE_PORT}'
      LOG_LEVEL: 'info'
      KAFKA_NUM_PARTITIONS: 1
      KAFKA_REPLICATION_FACTOR: 1
    logging:
      driver: json-file
      options:
        max-size: 100m

  data-broker-redis:
    image: dojot/redis:5.0.5-alpine3.10
    restart: always
    volumes:
      - data-broker-redis-volume:/data
    logging:
      driver: json-file
      options:
        max-size: 100m

  device-manager:
    image: dojot/device-manager:v0.5.0
    restart: always
    environment:
      # TODO: Fill these env variables with suitable values
      DEV_MNGR_CRYPTO_PASS: kamehameHA
      DEV_MNGR_CRYPTO_IV: 1234567890123456
      DEV_MNGR_CRYPTO_SALT: shuriken
      DBHOST: postgres
      DBUSER: devm
      DBPASS: devm
      LOG_LEVEL: INFO
    depends_on:
      - postgres
      - kafka
      - data-broker
      - device-manager-redis
    depends_on:
      postgres:
        condition: service_healthy
    logging:
      driver: json-file
      options:
        max-size: 100m

  device-manager-redis:
    image: dojot/redis:5.0.5-alpine3.10
    restart: always
    volumes:
      - device-manager-redis-volume:/data
    logging:
      driver: json-file
      options:
        max-size: 100m

  postgres:
    image: dojot/postgres:9.5.21-alpine
    environment:
      POSTGRES_DB: postgres
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: always
    volumes:
      - ./postgres/init-db.sh:/docker-entrypoint-initdb.d/init-db.sh:Z
      - postgres-volume:/var/lib/postgresql/data
    logging:
      driver: json-file
      options:
        max-size: 100m

  # Prepare database, Bootstrap the database
  kong-migrations:
    image: dojot/kong:v0.5.0
    command: kong migrations bootstrap
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: postgres
      KONG_PG_USER: kong
      KONG_PG_PASSWORD: "kong"
      KONG_PG_DATABASE: kong
      KONG_LOG_LEVEL: info
    restart: on-failure
    logging:
      driver: json-file
      options:
        max-size: 100m

  # Run any new migrations and Finish running any pending migrations after 'up'.
  kong-migrations-up:
    image:  dojot/kong:v0.5.0
    command: kong migrations up && kong migrations finish
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: postgres
      KONG_PG_USER: kong
      KONG_PG_PASSWORD: "kong"
      KONG_PG_DATABASE: kong
      KONG_LOG_LEVEL: info
    restart: on-failure
    logging:
      driver: json-file
      options:
        max-size: 100m

  apigw:
    image: dojot/kong:v0.5.0
    depends_on:
      postgres:
        condition: service_healthy
      kong-migrations:
        condition: service_started
      kong-migrations-up:
        condition: service_started
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: postgres
      KONG_PG_USER: kong
      KONG_PG_DATABASE: kong
      KONG_PG_PASSWORD: kong
      KONG_LOG_LEVEL: info
      # To enable HTTPs external, it is necessary to configure public certificates
      # issued by a public CA, such as lets encrypt in KONG_SSL_CERT.
      # KONG_SSL_CERT_KEY: /certs/example-external.key
      # KONG_SSL_CERT: /certs/example-external.crt
      # To enable HTTPs internal with mutual authentication, it is necessary to configure public certificates
      # issued by a EJBCA internal from dojot in KONG_NGINX_PROXY_PROXY_SSL_CERTIFICATE.
      # KONG_NGINX_PROXY_PROXY_SSL_CERTIFICATE_KEY: /certs/example-internal.key
      # KONG_NGINX_PROXY_PROXY_SSL_CERTIFICATE: /certs/example-internal.crt
      # Root cerficate from internal CA
      # KONG_NGINX_PROXY_PROXY_SSL_TRUSTED_CERTIFICATE: /certs/root-ca-internal.crt
      # KONG_NGINX_PROXY_PROXY_SSL_VERIFY: "on"
      # KONG_NGINX_PROXY_PROXY_SSL_VERIFY_DEPTH: "2"
    ports:
      - "8000:8000/tcp"
      # Proxy listen to HTTPS traffic (8443). services and routes must be configured to use the https protocol
      # Each service must have its certificate with Subject Alternative Name generated by dojot's EJBCA.
      #- "8443:8443/tcp"
    healthcheck:
      test: ["CMD", "kong", "health"]
      interval: 10s
      timeout: 10s
      retries: 10
    # Exposes certificates
    #volumes:
    #  - ./kong/certificates/:/certs/:Z
    restart: always
    logging:
      driver: json-file
      options:
        max-size: 100m

  kong-config:
    image: dojot/appropriate-curl
    entrypoint: /opt/kong.config.sh
    restart: on-failure
    depends_on:
      - apigw
    volumes:
      - ./kong/kong.config.sh:/opt/kong.config.sh:Z
    logging:
      driver: json-file
      options:
        max-size: 100m

  auth:
    image: dojot/auth:v0.5.0
    restart: always
    depends_on:
      - apigw
      - postgres
      - auth-redis
    environment:
      AUTH_DB_HOST: "postgres"
      AUTH_DB_USER: "auth"
      AUTH_DB_PWD:  "auth"
      AUTH_KONG_URL: "http://apigw:8001"
      AUTH_CACHE_HOST: "auth-redis"
      # This is used to select the type of cache to be used.
      # Allowed values are "redis" or "nocache"
      AUTH_CACHE_NAME: "redis"
      DOJOT_MANAGEMENT_USER: 'auth'
      KAFKA_GROUP_ID: 'auth-group'
    logging:
      driver: json-file
      options:
        max-size: 100m

  auth-redis:
    image: dojot/redis:5.0.5-alpine3.10
    restart: always
    volumes:
      - auth-redis-volume:/data
    logging:
      driver: json-file
      options:
        max-size: 100m

  zookeeper:
    image: "confluentinc/cp-zookeeper:5.5.0"
    restart: always
    environment:
      ZOOKEEPER_REPLICAS: "1"
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_ELECTION_PORT: 3888
      ZOOKEEPER_SERVER_PORT: 2888
      ZOOKEEPER_HEAP_SIZE: "2G"
      ZOOKEEPER_INIT_LIMIT: "5"
      ZOOKEEPER_LOG_LEVEL: "INFO"
      ZOOKEEPER_MAX_CLIENT_CNXNS: "100"
      ZOOKEEPER_MAX_SESSION_TIMEOUT: "40000"
      ZOOKEEPER_MIN_SESSION_TIMEOUT: "4000"
      ZOOKEEPER_PURGE_INTERVAL: "0"
      ZOOKEEPER_SNAP_RETAIN_COUNT: "3"
      ZOOKEEPER_SYNC_LIMIT: "10"
      ZOOKEEPER_TICK_TIME: "2000"
    volumes:
      - zookeeper-volume:/var/lib/zookeeper/data
      - zookeeper-log-volume:/var/lib/zookeeper/log
      - zookeeper-secrets-volume:/etc/zookeeper/secrets
    logging:
      driver: json-file
      options:
        max-size: 100m

  kafka:
    image: confluentinc/cp-kafka:5.5.0
    depends_on:
      - zookeeper
    restart: always
    hostname: "kafka"
    environment:
      KAFKA_BROKER_ID: "1"
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_LISTENERS: PLAINTEXT://:9092
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: "1"
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: "0"
      KAFKA_LOG_RETENTION_MINUTES: "30"
      KAFKA_LOG_SEGMENT_BYTES: "262144000"
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: "30000"
    volumes:
      - kafka-volume:/var/lib/kafka/data
      - kafka-secrets-volume:/etc/kafka/secrets
    logging:
      driver: json-file
      options:
        max-size: 100m

  kafka-ws:
    image: dojot/kafka-ws:v0.5.0
    depends_on:
      - kafka
      - kafka-ws-redis
    environment:
      KAFKA_WS_SERVER_JWT_EXP_TIME: "true"
      KAFKA_WS_REDIS_HOST: kafka-ws-redis
    restart: always
    logging:
      driver: json-file
      options:
        max-size: 100m

  kafka-ws-redis:
    image: dojot/redis:6.0.4-alpine3.11
    restart: always
    volumes:
      - kafka-ws-redis-volume:/data
    logging:
      driver: json-file
      options:
        max-size: 100m

  data-manager:
    image: dojot/data-manager:v0.5.0
    restart: always
    depends_on:
      - device-manager
    logging:
      driver: json-file
      options:
        max-size: 100m

  backstage:
    image: artifactory.cpqd.com.br/docker-dev/cpqd/dojot/backstage:2.2.2
    restart: always
    depends_on:
      - postgres
    logging:
      driver: json-file
      options:
        max-size: 100m

  cron:
    image: artifactory.cpqd.com.br/docker-dev/cpqd/dojot/cron:2.2.2
    depends_on:
      - kafka
      - data-broker
      - auth
      - mongodb
    restart: always
    logging:
      driver: json-file
      options:
        max-size: 100m


  binary-agent:
    image: artifactory.cpqd.com.br/docker-dev/cpqd/dojot/binary-agent:2.2.2
    depends_on:
      - kafka
    restart: always
    logging:
      driver: json-file
      options:
        max-size: 20m
        max-file: '5'
    environment:
      DEVICE_MANAGER_UNKNOWN_DEVICE_ID: 'b19b3d'
      LOG_LEVEL: 'info'
      
  meter-calc:
    image: artifactory.cpqd.com.br/docker-dev/cpqd/dojot/meter-calc:2.2.2
    #image: local/meter-calc:1.0
    restart: always
    environment:
      METERCALC_CONFIG_FILE: 'production.conf'
      OPERATION_DEVICE_ID: 'ddd4a'  
      CAMPUS_DEVICE_ID: '86ab65'
      LOG_LEVEL: 'debug'
    depends_on:
      - kafka
      - auth
      - history
      - device-manager
    ports:
      - 3000:3000
    logging:
      driver: json-file
      options:
        max-size: 20m
        max-file: '5'
      
  json-agent:
    image: artifactory.cpqd.com.br/docker-dev/cpqd/dojot/json-agent:2.2.2
    depends_on:
      - kafka
    restart: always
    environment:
      LOG_LEVEL: 'debug'
    logging:
      driver: json-file
      options:
        max-size: 20m
        max-file: '5'
    networks:
      - default

  rabbitmq:
    image: dojot/rabbitmq:3.7-alpine
    restart: always
    volumes:
      - rabbitmq-volume:/var/lib/rabbitmq
    logging:
      driver: json-file
      options:
        max-size: 100m
        
  rmq0: &rabbitmq
    image: rabbitmq:3.8.8
    restart: always
    logging:
      driver: json-file
      options:
        max-size: 100m
    ports:
      - "5673:5672"
      - "15673:15672"
      - "15693:15692"
    hostname: rmq0
    networks:
      - default
 
volumes:
  postgres-volume:
  mongodb-volume:
  mongodb-cfg-volume:
  rabbitmq-volume:
  zookeeper-volume:
  zookeeper-log-volume:
  zookeeper-secrets-volume:
  kafka-volume:
  kafka-secrets-volume:
  auth-redis-volume:
  data-broker-redis-volume:
  device-manager-redis-volume:
  kafka-ws-redis-volume:
